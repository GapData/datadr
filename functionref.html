<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>trelliscope R Function Reference</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Le styles -->
    <link href="bootstrap/css/bootstrap.css" rel="stylesheet">
    <link href="css/pygment.css" rel="stylesheet">
    <link href='css/highlight.css' rel='stylesheet'>
    <style type="text/css">
      body {
        padding-top: 20px;
        padding-bottom: 40px;
      }

      /* Custom container */
      .container-narrow {
        margin: 0 auto;
        max-width: 900px;
      }
      .container-narrow > hr {
        margin: 15px 0 20px 0;
      }
      
      #next {
         font-size: 14px;
      }

      #previous {
         font-size: 14px;
      }

      .fref_title {
         border-bottom:1px solid #EEE;
      }

      .myHeader {
         font-family: 'Chivo', 'Helvetica Neue', Helvetica, Arial, serif; font-weight: 400;
         letter-spacing: -1px;
         font-size: 28px;
         line-height: 40px;
         color: #d14;
         text-shadow: 8px 2px 6 rgba(55, 55, 55, 0.5);
      }

      .unselectable {
         -moz-user-select: none;
         -webkit-user-select: none;
         -ms-user-select: none;
      }

/*      #main-content {
         margin-top: -15px;
      }
*/
    </style>
    
    <link href="bootstrap/css/bootstrap-responsive.css" rel="stylesheet">

    <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="js/html5shiv.js"></script>
    <![endif]-->

    <!-- Fav and touch icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="ico/apple-touch-icon-144-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="114x114" href="ico/apple-touch-icon-114-precomposed.png">
      <link rel="apple-touch-icon-precomposed" sizes="72x72" href="ico/apple-touch-icon-72-precomposed.png">
                    <link rel="apple-touch-icon-precomposed" href="ico/apple-touch-icon-57-precomposed.png">
                                   <!-- <link rel="shortcut icon" href="ico/favicon.png"> -->
  </head>

  <body>

    <div class="container-narrow">

      <div class="masthead">
        <ul class="nav nav-pills pull-right">
          <li class=""><a href="index.html">Docs</a></li>
          <li class="active"><a href="functionref.html">Function Ref</a></li>
          <li><a href="https://www.github.com/hafen/datadr">Github</a></li>
        </ul>
        <p class="myHeader">datadr: R Function Reference</p>
      </div>

      <hr>

<div class="container-fluid">
   <div class="row-fluid">
   
   <div class="span3 well">
   <ul class = "nav nav-list" id="toc">
   <li class='nav-header'>Contents</li> <li class="active">
   <a target="_self" class="nav-not-header" href="#packagemain">Package Info</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#adddata">addData</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#adult">adult</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#asdataframeddf">as.data.frame.ddf</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#aslistddo">as.list.ddo</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#bsv">bsv</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#charfilehash">charFileHash</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#combcollect">combCollect</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#combddo">combDdo</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#combmean">combMean</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#combmeancoef">combMeanCoef</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#combrbind">combRbind</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#conddiv">condDiv</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#convert">convert</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#ddf-class">ddf-class</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#ddf">ddf</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#kvexample">kvExample</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#ddo">ddo</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#setattributes">setAttributes</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#digestfilehash">digestFileHash</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#divide">divide</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#dfsplit">dfSplit</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#drblb">drBLB</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#drfilter">drFilter</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#drglm">drGLM</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#drjoin">drJoin</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#drsample">drSample</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#getbsv">getBsv</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#getbsvs">getBsvs</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#getsplitvar">getSplitVar</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#getsplitvars">getSplitVars</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#hdfsconn">hdfsConn</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#kvapply">kvApply</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#lapplyddffunction-method">lapply,ddf,function-method</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#localdiskconn">localDiskConn</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#localdiskcontrol">localDiskControl</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#makeextractable">makeExtractable</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#mrexec">mrExec</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#tabulatemap">tabulateMap</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#printddo">print.ddo</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#quantileddf">quantile.ddf</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#readhdfstextfile">readHDFStextFile</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#readtextfilebychunk">readTextFileByChunk</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#recombine">recombine</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#removedata">removeData</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#rhipecontrol">rhipeControl</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#rrdiv">rrDiv</a>
</li>
<li class="">
   <a target="_self" class="nav-not-header" href="#updateattributes">updateAttributes</a>
</li>
   </ul>
   </div>

<div class="span9 tab-content" id="main-content">

<!-- packagemain -->   
<div class="tab-pane active" id="packagemain">

<h3>Divide and Recombine for Large, Complex Data</h3>

<p><strong>Author:</strong> Ryan Hafen</p>
<p><strong>Version:</strong> 0.6.1</p>
<p><strong>Date:</strong> 2014-02-17</p>
<p><strong>License:</strong> BSD</p>

<h4>Description</h4>
<p>Methods for dividing data into subsets, applying analytical
methods to the subsets, and recombining the results.  Comes with a generic
MapReduce interface as well.  Works with key-value pairs stored in memory,
on local disk, or on HDFS, in the latter case using the R and Hadoop
Integrated Programming Environment (RHIPE).</p>

<h4>Depends</h4>
<p>
R (&gt;= 2.15.1),
methods,
parallel,
data.table,
digest,
codetools,
testthat</p>

<h4>Suggests</h4>
<p></p>

</div>
<!-- addData -->   
<div class="tab-pane" id="adddata">

<h3 class="fref_title">Add Key-Value Pairs to a Data Connection</h3>

<h5>Usage</h5>
<pre>addData(conn, data, overwrite = FALSE)</pre>

<h5>Arguments</h5>
<dl>
  <dt>conn</dt>
  <dd>a kvConnection object</dd>
  <dt>data</dt>
  <dd>a list of key-value pairs (list of lists
  where each sub-list has two elements, the key and the
  value)</dd>
  <dt>overwrite</dt>
  <dd>if data with the same key is already
  present in the data, should it be overwritten? (does not
  work for HDFS connections)</dd>
</dl>

  <h5>Description</h5>

  <p>Add key-value pairs to a data connection</p>


  <h5>Note</h5>

  <p>This is generally not recommended for HDFS as it writes a
new file each time it is called, and can result in more
individual files than Hadoop likes to deal with.</p>




<h5>See also</h5>

<code><a href='#removedata'>removeData</a></code>, <code><a href='#localdiskconn'>localDiskConn</a></code>,
<code><a href='#hdfsconn'>hdfsConn</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- adult -->   
<div class="tab-pane" id="adult">

<h3 class="fref_title">"Census Income" Dataset</h3>

<h5>Usage</h5>
<pre>adult</pre>

  <h5>Format</h5>

  <p>(From UCI machine learning repository)</p>

  <p><ul>
<li> age. continuous
   </li>
<li> workclass. Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked
   </li>
<li> fnlwgt. continuous
   </li>
<li> education. Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool
   education-num: continuous
   </li>
<li> marital. Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse
   </li>
<li> occupation. Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces
   </li>
<li> relationship. Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried
   </li>
<li> race. White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black
   </li>
<li> sex. Female, Male
   </li>
<li> capgain. continuous
   </li>
<li> caploss. continuous
   </li>
<li> hoursperweek. continuous
   </li>
<li> nativecountry. United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands
   </li>
<li> income. <=50K, >50K
   </li>
<li> incomebin. 0 if income<=50K, 1 if income>50K
</li>
</ul></p>


  <h5>&quot;Census Income&quot; Dataset</h5>


  <h5>Description</h5>

  <p>"Census Income" dataset from UCI machine learning
repository</p>


  <h5>References</h5>

  <p>Bache, K. & Lichman, M. (2013). UCI Machine Learning
Repository [<a href = 'http://archive.ics.uci.edu/ml'>http://archive.ics.uci.edu/ml</a>]. Irvine,
CA: University of California, School of Information and
Computer Science.</p>



</div>


<!-- as.data.frame.ddf -->   
<div class="tab-pane" id="asdataframeddf">

<h3 class="fref_title">Turn 'ddf' Object into Data Frame</h3>

<h5>Usage</h5>
<pre>as.data.frame(x, row.names = NULL, optional = FALSE, keys = TRUE, splitVars = TRUE, 
  bsvs = FALSE, ...)</pre>

<h5>Arguments</h5>
<dl>
  <dt>x</dt>
  <dd>a 'ddf' object</dd>
  <dt>row.names</dt>
  <dd>passed to <code>as.data.frame</code></dd>
  <dt>optional</dt>
  <dd>passed to <code>as.data.frame</code></dd>
  <dt>keys</dt>
  <dd>should the key be added as a variable in the
  resulting data frame? (if key is not a character, it will
  be replaced with a md5 hash)</dd>
  <dt>splitVars</dt>
  <dd>should the values of the splitVars be
  added as variables in the resulting data frame?</dd>
  <dt>bsvs</dt>
  <dd>should the values of bsvs be added as
  variables in the resulting data frame?</dd>
  <dt>...</dt>
  <dd>additional arguments passed to
  as.data.frame</dd>
</dl>

  <h5>Description</h5>

  <p>Rbind all the rows of a 'ddf' object into a single data
frame</p>



</div>


<!-- as.list.ddo -->   
<div class="tab-pane" id="aslistddo">

<h3 class="fref_title">Turn 'ddo' / 'ddf' Object into a list</h3>

<h5>Usage</h5>
<pre>as.list(x, ...)</pre>

<h5>Arguments</h5>
<dl>
  <dt>x</dt>
  <dd>a 'ddo' / 'ddf' object</dd>
  <dt>...</dt>
  <dd>additional arguments passed to
  <code>as.list</code></dd>
</dl>

  <h5>Description</h5>

  <p>Turn 'ddo' / 'ddf' Object into a list</p>



</div>


<!-- bsv -->   
<div class="tab-pane" id="bsv">

<h3 class="fref_title">Construct Between Subset Variable (BSV)</h3>

<h5>Usage</h5>
<pre>bsv(val = NULL, desc = "")</pre>

<h5>Arguments</h5>
<dl>
  <dt>val</dt>
  <dd>a scalar character, numeric, or date</dd>
  <dt>desc</dt>
  <dd>a character string describing the BSV</dd>
</dl>

  <h5>Description</h5>

  <p>Construct between subset variable (BSV)</p>


  <h5>Details</h5>

  <p>Should be called inside the <code>bsvFn</code> argument to
<code>divide</code> used for constructing a BSV list for each
subset of a division.</p>




<h5>See also</h5>

<code><a href='#divide'>divide</a></code>, <code><a href='#getbsvs'>getBsvs</a></code>,
<code><a href='ddo-ddf-#accessors'>bsvInfo</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- charFileHash -->   
<div class="tab-pane" id="charfilehash">

<h3 class="fref_title">Character File Hash Function</h3>

<h5>Usage</h5>
<pre>charFileHash(keys, conn)</pre>

<h5>Arguments</h5>
<dl>
  <dt>keys</dt>
  <dd>keys to be hashed</dd>
  <dt>conn</dt>
  <dd>a "localDiskConn" object</dd>
</dl>

  <h5>Description</h5>

  <p>Function to be used to specify the file where key-value
pairs get stored for local disk connections, useful when
keys are scalar strings.  Should be passed as the argument
<code>fileHashFn</code> to <code><a href='#localdiskconn'>localDiskConn</a></code>.</p>


  <h5>Details</h5>

  <p>You shouldn't need to call this directly other than to
experiment with what the output looks like or to get ideas
on how to write your own custom hash.</p>




<h5>See also</h5>

<code>localDiskConn</code>, <code><a href='#digestfilehash'>digestFileHash</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- combCollect -->   
<div class="tab-pane" id="combcollect">

<h3 class="fref_title">"Collect" Recombination</h3>

<h5>Usage</h5>
<pre>combCollect(...)</pre>

<h5>Arguments</h5>
<dl>
  <dt>...</dt>
  <dd>...</dd>
</dl>

  <h5>Description</h5>

  <p>"Collect" recombination - simply collect the results into a
local list of key-value pairs</p>


  <h5>Details</h5>

  <p>This is an experimental prototype.  It is to be passed as
the argument <code>combine</code> to <code><a href='#recombine'>recombine</a></code>.</p>




<h5>See also</h5>

<code><a href='#divide'>divide</a></code>, <code><a href='#recombine'>recombine</a></code>,
<code><a href='#combddo'>combDdo</a></code>, <code><a href='#combmeancoef'>combMeanCoef</a></code>,
<code><a href='#combrbind'>combRbind</a></code>, <code><a href='#combmean'>combMean</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- combDdo -->   
<div class="tab-pane" id="combddo">

<h3 class="fref_title">"DDO" Recombination</h3>

<h5>Usage</h5>
<pre>combDdo(...)</pre>

<h5>Arguments</h5>
<dl>
  <dt>...</dt>
  <dd>...</dd>
</dl>

  <h5>Description</h5>

  <p>"DDO" recombination - simply collect the results into a
"ddo" object</p>


  <h5>Details</h5>

  <p>This is an experimental prototype.  It is to be passed as
the argument <code>combine</code> to <code><a href='#recombine'>recombine</a></code>.</p>




<h5>See also</h5>

<code><a href='#divide'>divide</a></code>, <code><a href='#recombine'>recombine</a></code>,
<code><a href='#combcollect'>combCollect</a></code>, <code><a href='#combmeancoef'>combMeanCoef</a></code>,
<code><a href='#combrbind'>combRbind</a></code>, <code><a href='#combmean'>combMean</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- combMean -->   
<div class="tab-pane" id="combmean">

<h3 class="fref_title">Mean Recombination</h3>

<h5>Usage</h5>
<pre>combMean(...)</pre>

<h5>Arguments</h5>
<dl>
  <dt>...</dt>
  <dd>...</dd>
</dl>

  <h5>Description</h5>

  <p>Mean recombination</p>


  <h5>Details</h5>

  <p>This is an experimental prototype.  It is to be passed as
the argument <code>combine</code> to <code><a href='#recombine'>recombine</a></code>.</p>




<h5>See also</h5>

<code><a href='#divide'>divide</a></code>, <code><a href='#recombine'>recombine</a></code>,
<code><a href='#combcollect'>combCollect</a></code>, <code><a href='#combddo'>combDdo</a></code>,
<code><a href='#combrbind'>combRbind</a></code>, <code><a href='#combmeancoef'>combMeanCoef</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- combMeanCoef -->   
<div class="tab-pane" id="combmeancoef">

<h3 class="fref_title">Mean Coefficient Recombination</h3>

<h5>Usage</h5>
<pre>combMeanCoef(...)</pre>

<h5>Arguments</h5>
<dl>
  <dt>...</dt>
  <dd>...</dd>
</dl>

  <h5>Description</h5>

  <p>Mean coefficient recombination</p>


  <h5>Details</h5>

  <p>This is an experimental prototype.  It is to be passed as
the argument <code>combine</code> to <code><a href='#recombine'>recombine</a></code>.  It
expects to be dealing with named vectors including an
element <code>n</code> specifying the number of rows in that
subset.</p>




<h5>See also</h5>

<code><a href='#divide'>divide</a></code>, <code><a href='#recombine'>recombine</a></code>,
<code><a href='#rrdiv'>rrDiv</a></code>, <code><a href='#combcollect'>combCollect</a></code>,
<code><a href='#combddo'>combDdo</a></code>, <code><a href='#combrbind'>combRbind</a></code>,
<code><a href='#combmean'>combMean</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- combRbind -->   
<div class="tab-pane" id="combrbind">

<h3 class="fref_title">"rbind" Recombination</h3>

<h5>Usage</h5>
<pre>combRbind(...)</pre>

<h5>Arguments</h5>
<dl>
  <dt>...</dt>
  <dd>...</dd>
</dl>

  <h5>Description</h5>

  <p>"rbind" recombination</p>


  <h5>Details</h5>

  <p>This is an experimental prototype.  It is to be passed as
the argument <code>combine</code> to <code><a href='#recombine'>recombine</a></code>.</p>




<h5>See also</h5>

<code><a href='#divide'>divide</a></code>, <code><a href='#recombine'>recombine</a></code>,
<code><a href='#combddo'>combDdo</a></code>, <code><a href='#combcollect'>combCollect</a></code>,
<code><a href='#combmeancoef'>combMeanCoef</a></code>, <code><a href='#combmean'>combMean</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- condDiv -->   
<div class="tab-pane" id="conddiv">

<h3 class="fref_title">Conditioning Variable Division</h3>

<h5>Usage</h5>
<pre>condDiv(vars)</pre>

<h5>Arguments</h5>
<dl>
  <dt>vars</dt>
  <dd>a character string or vector of character
  strings specifying the variables of the input data across
  which to divide</dd>
</dl>

  <h5>Value</h5>

  <p>a list to be used for the "by" argument to
<code><a href='#divide'>divide</a></code></p>


  <h5>Description</h5>

  <p>Specify conditioning variable division parameters for data
division</p>


  <h5>Details</h5>

  <p>Currently each unique combination of values of <code>vars</code>
constitutes a subset.  In the future, specifying shingles
for numeric conditioning variables will be implemented.</p>


  <h5>References</h5>

  <p><ul>
<li> <a href = 'http://www.datadr.org'>http://www.datadr.org</a> </li>
<li>
<a href = 'http://onlinelibrary.wiley.com/doi/10.1002/sta4.7/full'>Guha,
S., Hafen, R., Rounds, J., Xia, J., Li, J., Xi, B., &
Cleveland, W. S. (2012). Large complex data: divide and
recombine (D&R) with RHIPE. <em>Stat</em>, 1(1), 53-67.</a> </li>
</ul></p>

  <p></p>




<h5>See also</h5>

<code><a href='#divide'>divide</a></code>, <code><a href='#getsplitvars'>getSplitVars</a></code>,
<code><a href='#getsplitvar'>getSplitVar</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- convert -->   
<div class="tab-pane" id="convert">

<h3 class="fref_title">Convert 'ddo' / 'ddf' Objects</h3>

<h5>Usage</h5>
<pre>convert(from, to)</pre>

<h5>Arguments</h5>
<dl>
  <dt>from</dt>
  <dd>a 'ddo' or 'ddf' object</dd>
  <dt>to</dt>
  <dd>a 'kvConnection' object (created with
  <code><a href='#localdiskconn'>localDiskConn</a></code> or <code><a href='#hdfsconn'>hdfsConn</a></code>) or
  <code>NULL</code> if an in-memory 'ddo' / 'ddf' is desired</dd>
</dl>

  <h5>Description</h5>

  <p>Convert 'ddo' / 'ddf' objects between different storage
backends</p>



</div>


<!-- ddf-class -->   
<div class="tab-pane" id="ddf-class">

<h3 class="fref_title">'ddf' accessors</h3>

<h5>Usage</h5>
<pre>nrow(x)

NROW(x)

ncol(x)

NCOL(x)

nrow(x)

NROW(x)

ncol(x)

NCOL(x)</pre>

<h5>Arguments</h5>
<dl>
  <dt>x</dt>
  <dd>a 'ddf' object</dd>
</dl>

  <h5>Description</h5>

  <p>'ddf' accessors</p>

  <p>'ddf' accessors</p>

  <p>'ddf' accessors</p>

  <p>'ddf' accessors</p>

  <p>The Number of Rows/Columns of a 'ddf' object</p>



</div>


<!-- ddf -->   
<div class="tab-pane" id="ddf">

<h3 class="fref_title">Instantiate a Distributed Data Frame ('ddf')
Instantiate a distributed data frame ('ddf')</h3>

<h5>Usage</h5>
<pre>ddf(conn, transFn = identity, update = FALSE, reset = FALSE, control = NULL, verbose = TRUE)</pre>

<h5>Arguments</h5>
<dl>
  <dt>conn</dt>
  <dd>an object pointing to where data is or will
  be stored for the 'ddf' object - can be a 'kvConnection'
  object created from <code><a href='#localdiskconn'>localDiskConn</a></code> or
  <code><a href='#hdfsconn'>hdfsConn</a></code>, or a data frame or list of
  key-value pairs</dd>
  <dt>transFn</dt>
  <dd>transFn a function to be applied to the
  key-value pairs of this data prior to doing any
  processing, that transform the data into a data frame if
  it is not stored as such</dd>
  <dt>update</dt>
  <dd>should the attributes of this object be
  updated?  See <code><a href='#updateattributes'>updateAttributes</a></code> for more
  details.</dd>
  <dt>reset</dt>
  <dd>should all persistent metadata about this
  object be removed and the object created from scratch?
  This setting does not effect data stored in the
  connection location.</dd>
  <dt>control</dt>
  <dd>parameters specifying how the backend
  should handle things if attributes are updated
  (most-likely parameters to <code>rhwatch</code> in RHIPE) - see
  <code><a href='#rhipecontrol'>rhipeControl</a></code> and
  <code><a href='#localdiskcontrol'>localDiskControl</a></code></dd>
  <dt>verbose</dt>
  <dd>logical - print messages about what is
  being done</dd>
</dl>

  <h5>Description</h5>

  <p>Instantiate a Distributed Data Frame ('ddf') Instantiate a
distributed data frame ('ddf')</p>



</div>


<!-- kvExample -->   
<div class="tab-pane" id="kvexample">

<h3 class="fref_title">Accessor Functions</h3>

<h5>Usage</h5>
<pre>kvExample(x, transform = FALSE)

bsvInfo(x)

counters(x)

splitSizeDistn(x)

splitRowDistn(x)

getKeys(x)

summary(object, ...)

hasExtractableKV(x)

names(x)

length(x)</pre>

<h5>Arguments</h5>
<dl>
  <dt>x</dt>
  <dd>a 'ddf'/'ddo' object</dd>
  <dt>transform</dt>
  <dd>if the 'ddf' object has a
  <code>transFn</code>, should it be applied prior to returning?</dd>
  <dt>object</dt>
  <dd>a 'ddf'/'ddo' object</dd>
  <dt>...</dt>
  <dd>additional arguments</dd>
</dl>

  <h5>Description</h5>

  <p>Accessor functions for attributes of ddo/ddf objects.
Methods also include <code>nrow</code> and <code>ncol</code> for ddf
objects.</p>

  <p>Accessor methods for 'ddo' and 'ddf' objects</p>



</div>


<!-- ddo -->   
<div class="tab-pane" id="ddo">

<h3 class="fref_title">Instantiate a Distributed Data Object ('ddo')
Instantiate a distributed data object ('ddo')</h3>

<h5>Usage</h5>
<pre>ddo(conn, update = FALSE, reset = FALSE, control = NULL, verbose = TRUE)</pre>

<h5>Arguments</h5>
<dl>
  <dt>conn</dt>
  <dd>an object pointing to where data is or will
  be stored for the 'ddf' object - can be a 'kvConnection'
  object created from <code><a href='#localdiskconn'>localDiskConn</a></code> or
  <code><a href='#hdfsconn'>hdfsConn</a></code>, or a data frame or list of
  key-value pairs</dd>
  <dt>update</dt>
  <dd>should the attributes of this object be
  updated?  See <code><a href='#updateattributes'>updateAttributes</a></code> for more
  details.</dd>
  <dt>reset</dt>
  <dd>should all persistent metadata about this
  object be removed and the object created from scratch?
  This setting does not effect data stored in the
  connection location.</dd>
  <dt>control</dt>
  <dd>parameters specifying how the backend
  should handle things if attributes are updated
  (most-likely parameters to <code>rhwatch</code> in RHIPE) - see
  <code><a href='#rhipecontrol'>rhipeControl</a></code> and
  <code><a href='#localdiskcontrol'>localDiskControl</a></code></dd>
  <dt>verbose</dt>
  <dd>logical - print messages about what is
  being done</dd>
</dl>

  <h5>Description</h5>

  <p>Instantiate a Distributed Data Object ('ddo') Instantiate a
distributed data object ('ddo')</p>



</div>


<!-- setAttributes -->   
<div class="tab-pane" id="setattributes">

<h3 class="fref_title">Managing attributes of 'ddo' or 'ddf' objects</h3>

<h5>Usage</h5>
<pre>setAttributes(obj, ...)

setAttributes(obj, attrs)

getAttribute(obj, attrName)

getAttributes(obj, ...)

getAttributes(obj, attrNames)

hasAttributes(obj, ...)

hasAttributes(obj, attrNames)</pre>

<h5>Arguments</h5>
<dl>
  <dt>attrs</dt>
  <dd>a named list of attributes to set</dd>
  <dt>obj</dt>
  <dd>'ddo' or 'ddf' object</dd>
  <dt>attrName</dt>
  <dd>name of the attribute to get</dd>
  <dt>...</dt>
  <dd>additional arguments</dd>
  <dt>attrNames</dt>
  <dd>vector of names of the attributes to
  get</dd>
</dl>

  <h5>Description</h5>

  <p>Managing attributes of 'ddo' or 'ddf' objects</p>



</div>


<!-- digestFileHash -->   
<div class="tab-pane" id="digestfilehash">

<h3 class="fref_title">Digest File Hash Function</h3>

<h5>Usage</h5>
<pre>digestFileHash(keys, conn)</pre>

<h5>Arguments</h5>
<dl>
  <dt>keys</dt>
  <dd>keys to be hashed</dd>
  <dt>conn</dt>
  <dd>a "localDiskConn" object</dd>
</dl>

  <h5>Description</h5>

  <p>Function to be used to specify the file where key-value
pairs get stored for local disk connections, useful when
keys are arbitrary objects.  File names are determined
using a md5 hash of the object.  This is the default
argument for <code>fileHashFn</code> in
<code><a href='#localdiskconn'>localDiskConn</a></code>.</p>


  <h5>Details</h5>

  <p>You shouldn't need to call this directly other than to
experiment with what the output looks like or to get ideas
on how to write your own custom hash.</p>




<h5>See also</h5>

<code>localDiskConn</code>, <code><a href='#charfilehash'>charFileHash</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- divide -->   
<div class="tab-pane" id="divide">

<h3 class="fref_title">Divide a Distributed Data Object</h3>

<h5>Usage</h5>
<pre>divide(data, by = NULL, spill = 1e+06, filterFn = NULL, bsvFn = NULL, output = NULL, 
  preTransFn = NULL, postTransFn = NULL, control = NULL, update = FALSE, verbose = TRUE)</pre>

<h5>Arguments</h5>
<dl>
  <dt>data</dt>
  <dd>an object of class "ddf" or "ddo" - in the
  latter case, need to specify <code>preTransFn</code> to coerce
  each subset into a data frame</dd>
  <dt>by</dt>
  <dd>specification of how to divide the data -
  conditional (factor-level or shingles), random replicate,
  or near-exact replicate (to come) -- see details</dd>
  <dt>bsvFn</dt>
  <dd>a function to be applied to each subset that
  returns a list of between subset variables (BSVs)</dd>
  <dt>output</dt>
  <dd>a "kvConnection" object indicating where
  the output data should reside (see
  <code><a href='#localdiskconn'>localDiskConn</a></code>, <code><a href='#hdfsconn'>hdfsConn</a></code>).  If
  <code>NULL</code> (default), output will be an in-memory "ddo"
  object.</dd>
  <dt>spill</dt>
  <dd>integer telling the division method how many
  lines of data should be collected until spilling over
  into a new key-value pair</dd>
  <dt>filterFn</dt>
  <dd>a function that is applied to each
  candidate output key-value pair to determine whether it
  should be (if returns <code>TRUE</code>) part of the resulting
  division</dd>
  <dt>preTransFn</dt>
  <dd>a transformation function (if desired)
  to applied to eah subset prior to division</dd>
  <dt>postTransFn</dt>
  <dd>a transformation function (if desired)
  to apply to each post-division subset</dd>
  <dt>control</dt>
  <dd>parameters specifying how the backend
  should handle things (most-likely parameters to
  <code>rhwatch</code> in RHIPE) - see <code><a href='#rhipecontrol'>rhipeControl</a></code>
  and <code><a href='#localdiskcontrol'>localDiskControl</a></code></dd>
  <dt>update</dt>
  <dd>should a MapReduce job be run to obtain
  additional attributes for the result data prior to
  returning?</dd>
  <dt>verbose</dt>
  <dd>logical - print messages about what is
  being done</dd>
</dl>

  <h5>Value</h5>

  <p>an object of class "ddf" if the resulting subsets are data
frames.  Otherwise, an object of class "ddo".</p>


  <h5>Description</h5>

  <p>Divide a ddo/ddf object into subsets based on different
criteria</p>


  <h5>Details</h5>

  <p>The division methods this function will support include
conditioning variable division for factors (implemented --
see <code><a href='#conddiv'>condDiv</a></code>), conditioning variable division
for numerical variables through shingles, random replicate
(implemented -- see <code><a href='#rrdiv'>rrDiv</a></code>), and near-exact
replicate.  If <code>by</code> is a vector of variable names, the
data will be divided by these variables.  Alternatively,
this can be specified by e.g.  <code>condDiv(c("var1",
"var2"))</code>.</p>


  <h5>References</h5>

  <p><ul>
<li> <a href = 'http://www.datadr.org'>http://www.datadr.org</a> </li>
<li>
<a href = 'http://onlinelibrary.wiley.com/doi/10.1002/sta4.7/full'>Guha,
S., Hafen, R., Rounds, J., Xia, J., Li, J., Xi, B., &
Cleveland, W. S. (2012). Large complex data: divide and
recombine (D&R) with RHIPE. <em>Stat</em>, 1(1), 53-67.</a> </li>
</ul></p>

  <p></p>




<h5>See also</h5>

<code><a href='#recombine'>recombine</a></code>, <code><a href='#ddo'>ddo</a></code>,
<code><a href='#ddf'>ddf</a></code>, <code><a href='#conddiv'>condDiv</a></code>,
<code><a href='#rrdiv'>rrDiv</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- dfSplit -->   
<div class="tab-pane" id="dfsplit">

<h3 class="fref_title">Functions used in divide()</h3>

<h5>Usage</h5>
<pre>dfSplit(curDF, by, seed)

addSplitAttrs(curSplit, bsvFn, by, postTransFn = NULL)</pre>

<h5>Arguments</h5>
<dl>
  <dt>curDF,seed</dt>
  <dd>arguments</dd>
  <dt>curSplit,bsvFn,by,postTransFn</dt>
  <dd>arguments</dd>
</dl>

  <h5>Description</h5>

  <p>Functions used in divide()</p>



</div>


<!-- drBLB -->   
<div class="tab-pane" id="drblb">

<h3 class="fref_title">Bag of Little Bootstraps Recombination 'apply' Method</h3>

<h5>Usage</h5>
<pre>drBLB(statistic, metric, R, n)</pre>

<h5>Arguments</h5>
<dl>
  <dt>statistic</dt>
  <dd>a function to apply to each subset
  specifying the statistic to compute.  Must have arguments
  'data' and 'weights' - see details).  Must return a
  vector, where each element is a statistic of interest.</dd>
  <dt>metric</dt>
  <dd>a function specifying the metric to be
  applied to the <code>R</code> bootstrap samples of each
  statistic returned by <code>statistic</code>.  Expects an input
  vector and should output a vector.</dd>
  <dt>R</dt>
  <dd>the number of bootstrap samples</dd>
  <dt>n</dt>
  <dd>the total number of observations in the data</dd>
</dl>

  <h5>Description</h5>

  <p>Bag of little bootstraps recombination 'apply' method</p>


  <h5>Details</h5>

  <p>It is necessary to specify <code>weights</code> as a parameter to
the <code>statistic</code> function because for BLB to work
efficiently, it must resample each time with a sample of
size <code>n</code>.  To make this computationally possible for
very large <code>n</code>, we can use <code>weights</code> (see
reference for details).  Therefore, only methods with a
weights option can legitimately be used here.</p>


  <h5>References</h5>

  <p>BLB paper</p>




<h5>See also</h5>

<code><a href='#divide'>divide</a></code>, <code><a href='#recombine'>recombine</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- drFilter -->   
<div class="tab-pane" id="drfilter">

<h3 class="fref_title">Filter a 'ddo' or 'ddf' Object</h3>

<h5>Usage</h5>
<pre>drFilter(x, filterFn, output = NULL, control = NULL)</pre>

<h5>Arguments</h5>
<dl>
  <dt>x</dt>
  <dd>an object of class 'ddo' or 'ddf'</dd>
  <dt>filterFn</dt>
  <dd>function that takes the keys and/or
  values and returns either <code>TRUE</code> or <code>FALSE</code> -
  if <code>TRUE</code>, that key-value pair will be present in
  the result</dd>
  <dt>output</dt>
  <dd>a "kvConnection" object indicating where
  the output data should reside (see
  <code><a href='#localdiskconn'>localDiskConn</a></code>, <code><a href='#hdfsconn'>hdfsConn</a></code>).  If
  <code>NULL</code> (default), output will be an in-memory "ddo"
  object.</dd>
  <dt>control</dt>
  <dd>parameters specifying how the backend
  should handle things (most-likely parameters to
  <code>rhwatch</code> in RHIPE) - see <code><a href='#rhipecontrol'>rhipeControl</a></code>
  and <code><a href='#localdiskcontrol'>localDiskControl</a></code></dd>
</dl>

  <h5>Value</h5>

  <p>a 'ddo' or 'ddf' object</p>


  <h5>Description</h5>

  <p>Filter a 'ddo' or 'ddf' object</p>




<h5>See also</h5>

<code><a href='#drjoin'>drJoin</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- drGLM -->   
<div class="tab-pane" id="drglm">

<h3 class="fref_title">GLM Recombination 'apply' Method</h3>

<h5>Usage</h5>
<pre>drGLM(...)</pre>

<h5>Arguments</h5>
<dl>
  <dt>...</dt>
  <dd>arguments you would pass to the
  <code><a href='http://www.inside-r.org/r-doc/stats/glm'>glm</a></code> function</dd>
</dl>

  <h5>Description</h5>

  <p>GLM recombination 'apply' method</p>


  <h5>Details</h5>

  <p>This provides a function to be called for each subset in a
recombination MapReduce job that applies R's glm method and
outputs the coefficients.  It is to be passed as the
argument <code>method</code> to <code><a href='#recombine'>recombine</a></code>.</p>




<h5>See also</h5>

<code><a href='#divide'>divide</a></code>, <code><a href='#recombine'>recombine</a></code>,
<code><a href='#rrdiv'>rrDiv</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- drJoin -->   
<div class="tab-pane" id="drjoin">

<h3 class="fref_title">Join Two Data Sources by Key</h3>

<h5>Usage</h5>
<pre>drJoin(..., output = NULL, postTransFn = NULL, control = NULL)</pre>

<h5>Arguments</h5>
<dl>
  <dt>...</dt>
  <dd>named lists of input objects - assumed that
  all are of same type (all HDFS, all localDisk, all
  in-memory)</dd>
  <dt>output</dt>
  <dd>a "kvConnection" object indicating where
  the output data should reside (see
  <code><a href='#localdiskconn'>localDiskConn</a></code>, <code><a href='#hdfsconn'>hdfsConn</a></code>).  If
  <code>NULL</code> (default), output will be an in-memory "ddo"
  object.</dd>
  <dt>postTransFn</dt>
  <dd>an optional function to be applied to
  the each final key-value pair after joining</dd>
  <dt>control</dt>
  <dd>parameters specifying how the backend
  should handle things (most-likely parameters to
  <code>rhwatch</code> in RHIPE) - see <code><a href='#rhipecontrol'>rhipeControl</a></code>
  and <code><a href='#localdiskcontrol'>localDiskControl</a></code></dd>
</dl>

  <h5>Value</h5>

  <p>a 'ddo' object stored in the <code>output</code> connection,
where the values are named lists with names according to
the names given to the input data objects, and values are
the corresponding data</p>


  <h5>Description</h5>

  <p>Join two data sources by key</p>




<h5>See also</h5>

<code><a href='#drfilter'>drFilter</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- drSample -->   
<div class="tab-pane" id="drsample">

<h3 class="fref_title">Take a Sample of Key-Value Pairs
Take a sample of key-value Pairs</h3>

<h5>Usage</h5>
<pre>drSample(x, fraction, output = NULL, control = NULL)</pre>

<h5>Arguments</h5>
<dl>
  <dt>x</dt>
  <dd>a 'ddo' or 'ddf' object</dd>
  <dt>fraction</dt>
  <dd>fraction of key-value pairs to keep
  (between 0 and 1)</dd>
  <dt>output</dt>
  <dd>a "kvConnection" object indicating where
  the output data should reside (see
  <code><a href='#localdiskconn'>localDiskConn</a></code>, <code><a href='#hdfsconn'>hdfsConn</a></code>).  If
  <code>NULL</code> (default), output will be an in-memory "ddo"
  object.</dd>
  <dt>control</dt>
  <dd>parameters specifying how the backend
  should handle things (most-likely parameters to
  <code>rhwatch</code> in RHIPE) - see <code><a href='#rhipecontrol'>rhipeControl</a></code>
  and <code><a href='#localdiskcontrol'>localDiskControl</a></code></dd>
</dl>

  <h5>Description</h5>

  <p>Take a Sample of Key-Value Pairs Take a sample of key-value
Pairs</p>



</div>


<!-- getBsv -->   
<div class="tab-pane" id="getbsv">

<h3 class="fref_title">Get Between Subset Variable</h3>

<h5>Usage</h5>
<pre>getBsv(x, name)</pre>

<h5>Arguments</h5>
<dl>
  <dt>x</dt>
  <dd>a key-value pair or a value</dd>
  <dt>name</dt>
  <dd>the name of the BSV to get</dd>
</dl>

  <h5>Description</h5>

  <p>For a given key-value pair, get a BSV variable value by
name (if present)</p>



</div>


<!-- getBsvs -->   
<div class="tab-pane" id="getbsvs">

<h3 class="fref_title">Get Between Subset Variables</h3>

<h5>Usage</h5>
<pre>getBsvs(x)</pre>

<h5>Arguments</h5>
<dl>
  <dt>x</dt>
  <dd>a key-value pair or a value</dd>
</dl>

  <h5>Description</h5>

  <p>For a given key-value pair, exract all BSVs</p>



</div>


<!-- getSplitVar -->   
<div class="tab-pane" id="getsplitvar">

<h3 class="fref_title">Extract "Split" Variable</h3>

<h5>Usage</h5>
<pre>getSplitVar(x, name)</pre>

<h5>Arguments</h5>
<dl>
  <dt>x</dt>
  <dd>a key-value pair or a value</dd>
  <dt>name</dt>
  <dd>the name of the split variable to get</dd>
</dl>

  <h5>Description</h5>

  <p>For a given key-value pair or value, get a split variable
value by name, if present (split variables are variables
that define how the data was divided).</p>



</div>


<!-- getSplitVars -->   
<div class="tab-pane" id="getsplitvars">

<h3 class="fref_title">Extract "Split" Variables</h3>

<h5>Usage</h5>
<pre>getSplitVars(x)</pre>

<h5>Arguments</h5>
<dl>
  <dt>x</dt>
  <dd>a key-value pair or a value</dd>
</dl>

  <h5>Description</h5>

  <p>For a given k/v pair or value, exract all split variables
(split variables are variables that define how the data was
divided).</p>



</div>


<!-- hdfsConn -->   
<div class="tab-pane" id="hdfsconn">

<h3 class="fref_title">Connect to Data Source on HDFS</h3>

<h5>Usage</h5>
<pre>hdfsConn(loc, type = "sequence", autoYes = FALSE, reset = FALSE, verbose = TRUE)</pre>

<h5>Arguments</h5>
<dl>
  <dt>loc</dt>
  <dd>location on HDFS for the data source</dd>
  <dt>type</dt>
  <dd>the type of data ("map", "sequence", "text")</dd>
  <dt>autoYes</dt>
  <dd>automatically answer "yes" to questions
  about creating a path on HDFS</dd>
  <dt>reset</dt>
  <dd>should existing metadata for this object be
  overwritten?</dd>
  <dt>verbose</dt>
  <dd>logical - print messages about what is
  being done</dd>
</dl>

  <h5>Value</h5>

  <p>a "kvConnection" object of class "hdfsConn"</p>


  <h5>Description</h5>

  <p>Connect to a data source on HDFS</p>


  <h5>Details</h5>

  <p>This simply creates a "connection" to a directory on HDFS
(which need not have data in it).  To actually do things
with this data, see <code><a href='#ddo'>ddo</a></code>, etc.</p>




<h5>See also</h5>

<code>addData</code>, <code><a href='#ddo'>ddo</a></code>, <code><a href='#ddf'>ddf</a></code>,
<code><a href='#localdiskconn'>localDiskConn</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- kvApply -->   
<div class="tab-pane" id="kvapply">

<h3 class="fref_title">Apply Function to Key-Value Pair</h3>

<h5>Usage</h5>
<pre>kvApply(fn, kvPair, returnKV = FALSE)</pre>

<h5>Arguments</h5>
<dl>
  <dt>fn</dt>
  <dd>a function</dd>
  <dt>kvPair</dt>
  <dd>a key-value pair (a list with 2 elements)</dd>
  <dt>returnKV</dt>
  <dd>should the key and value be returned?</dd>
</dl>

  <h5>Description</h5>

  <p>Apply a function to a single key-value pair - not a
traditional R "apply" function.</p>


  <h5>Details</h5>

  <p>Determines how a function should be applied to a key-value
pair and then applies it: if the function has two formals,
it applies the function giving it the key and the value as
the arguments; if the function has one formal, it applies
the function giving it just the value.  This provides
flexibility and simplicity for when a function is only
meant to be applied to the value, but still allows keys to
be used if desired.</p>



</div>


<!-- lapply,ddf,function-method -->   
<div class="tab-pane" id="lapplyddffunction-method">

<h3 class="fref_title">Apply a function to all key/value pairs of a ddo/ddf object</h3>

<h5>Usage</h5>
<pre>lapply(X, FUN)

lapply(X, FUN)</pre>

<h5>Arguments</h5>
<dl>
  <dt>X</dt>
  <dd>the ddo/ddf object to apply the function to</dd>
  <dt>FUN</dt>
  <dd>the function to be applied to the value of
  each key/value pair</dd>
</dl>

  <h5>Value</h5>

  <p>a new ddo object</p>


  <h5>Description</h5>

  <p>This function creates a new ddo object by applying a
function to all key/value pairs of a ddo/ddf object.</p>



</div>


<!-- localDiskConn -->   
<div class="tab-pane" id="localdiskconn">

<h3 class="fref_title">Connect to Data Source on Local Disk</h3>

<h5>Usage</h5>
<pre>localDiskConn(loc, nBins = 0, fileHashFn = NULL, autoYes = FALSE, reset = FALSE, 
  verbose = TRUE)</pre>

<h5>Arguments</h5>
<dl>
  <dt>loc</dt>
  <dd>location on local disk for the data source</dd>
  <dt>nBins</dt>
  <dd>number of bins (subdirectories) to put data
  files into - if anticipating a large number of k/v pairs,
  it is a good idea to set this to something bigger than 0</dd>
  <dt>fileHashFn</dt>
  <dd>an optional function that operates on
  each key-value pair to determine the subdirectory
  structure for where the data should be stored for that
  subset, or can be specified "asis" when keys are scalar
  strings</dd>
  <dt>autoYes</dt>
  <dd>automatically answer "yes" to questions
  about creating a path on local disk</dd>
  <dt>reset</dt>
  <dd>should existing metadata for this object be
  overwritten?</dd>
  <dt>verbose</dt>
  <dd>logical - print messages about what is
  being done</dd>
</dl>

  <h5>Value</h5>

  <p>a "kvConnection" object of class "localDiskConn"</p>


  <h5>Description</h5>

  <p>Connect to a data source on local disk</p>


  <h5>Details</h5>

  <p>This simply creates a "connection" to a directory on local
disk (which need not have data in it).  To actually do
things with this connection, see <code><a href='#ddo'>ddo</a></code>, etc.
Typically, you should just use <code>loc</code> to specify where
the data is or where you would like data for this
connection to be stored.  Metadata for the object is also
stored in this directory.</p>




<h5>See also</h5>

<code>addData</code>, <code><a href='#ddo'>ddo</a></code>, <code><a href='#ddf'>ddf</a></code>,
<code><a href='#localdiskconn'>localDiskConn</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- localDiskControl -->   
<div class="tab-pane" id="localdiskcontrol">

<h3 class="fref_title">Specify Control Parameters for MapReduce on a Local Disk Connection</h3>

<h5>Usage</h5>
<pre>localDiskControl(cluster = NULL, map_buff_size_bytes = 10485760, reduce_buff_size_bytes = 10485760, 
  map_temp_buff_size_bytes = 10485760)</pre>

<h5>Arguments</h5>
<dl>
  <dt>cluster</dt>
  <dd>a "cluster" object obtained from
  <code><a href='http://www.inside-r.org/r-doc/parallel/makeCluster'>makeCluster</a></code> to allow for parallel
  processing</dd>
  <dt>map_buff_size_bytes</dt>
  <dd>determines how much data
  should be sent to each map task</dd>
  <dt>reduce_buff_size_bytes</dt>
  <dd>determines how much data
  should be sent to each reduce task</dd>
  <dt>map_temp_buff_size_bytes</dt>
  <dd>determines the size of
  chunks written to disk in between the map and reduce</dd>
</dl>

  <h5>Description</h5>

  <p>Specify control parameters for a MapReduce on a local disk
connection.  Currently the parameters include:</p>


  <h5>Note</h5>

  <p>If you have data on a shared drive that multiple nodes can
access or a high performance shared file system like
Lustre, you can run a local disk MapReduce job on multiple
nodes by creating a multi-node cluster with
<code><a href='http://www.inside-r.org/r-doc/parallel/makeCluster'>makeCluster</a></code>.</p>

  <p>If you are using multiple cores and the input data is very
small, <code>map_buff_size_bytes</code> needs to be small so that
the key-value pairs will be split across cores.</p>



</div>


<!-- makeExtractable -->   
<div class="tab-pane" id="makeextractable">

<h3 class="fref_title">Take a ddo/ddf HDFS data object and turn it into a mapfile</h3>

<h5>Usage</h5>
<pre>makeExtractable(obj)</pre>

<h5>Arguments</h5>
<dl>
  <dt>obj</dt>
  <dd>object of class 'ddo' or 'ddf' with an HDFS
  connection</dd>
</dl>

  <h5>Description</h5>

  <p>Take a ddo/ddf HDFS data object and turn it into a mapfile</p>



</div>


<!-- mrExec -->   
<div class="tab-pane" id="mrexec">

<h3 class="fref_title">Execute a MapReduce Job</h3>

<h5>Usage</h5>
<pre>mrExec(data, setup = NULL, map = NULL, reduce = NULL, output = NULL, control = NULL, 
  params = NULL, verbose = TRUE)</pre>

<h5>Arguments</h5>
<dl>
  <dt>data</dt>
  <dd>a ddo/ddf object, or list of ddo/ddf objects</dd>
  <dt>setup</dt>
  <dd>an expression of R code (created using the R
  command <code>expression</code>) to be run before map and
  reduce</dd>
  <dt>map</dt>
  <dd>an R expression that is evaluated during the
  map stage. For each task, this expression is executed
  multiple times (see details).</dd>
  <dt>reduce</dt>
  <dd>a vector of R expressions with names pre,
  reduce, and post that is evaluated during the reduce
  stage. For example <code>reduce = expression(pre={...},
  reduce={...}, post={...})</code>. reduce is optional, and if
  not specified the map output key-value pairs will be the
  result. If it is not specified, then a default identity
  reduce is performed. Setting it to 0 will skip the reduce
  altogether.</dd>
  <dt>output</dt>
  <dd>a "kvConnection" object indicating where
  the output data should reside (see
  <code><a href='#localdiskconn'>localDiskConn</a></code>, <code><a href='#hdfsconn'>hdfsConn</a></code>).  If
  <code>NULL</code> (default), output will be an in-memory "ddo"
  object.</dd>
  <dt>control</dt>
  <dd>parameters specifying how the backend
  should handle things (most-likely parameters to
  <code>rhwatch</code> in RHIPE) - see <code><a href='#rhipecontrol'>rhipeControl</a></code>
  and <code><a href='#localdiskcontrol'>localDiskControl</a></code></dd>
  <dt>params</dt>
  <dd>a named list of parameters external to the
  input data that are needed in the map or reduce phases</dd>
  <dt>verbose</dt>
  <dd>logical - print messages about what is
  being done</dd>
</dl>

  <h5>Value</h5>

  <p>"ddo" object - to keep it simple.  It is up to the user to
update or cast as "ddf" if that is the desired result.</p>


  <h5>Description</h5>

  <p>Execute a MapReduce job</p>




<h5>Author</h5>

Ryan Hafen

</div>


<!-- tabulateMap -->   
<div class="tab-pane" id="tabulatemap">

<h3 class="fref_title">Functions to Compute Summary Statistics in MapReduce</h3>

<h5>Usage</h5>
<pre>tabulateMap(formula, data)

tabulateReduce(result, reduce.values)

calculateMoments(y, order = 1, na.rm = TRUE)

combineMoments(m1, m2)

combineMultipleMoments(...)

moments2statistics(m)</pre>

<h5>Arguments</h5>
<dl>
  <dt>formula</dt>
  <dd>a formula to be used in
  <code><a href='http://www.inside-r.org/r-doc/stats/xtabs'>xtabs</a></code></dd>
  <dt>data</dt>
  <dd>a subset of a 'ddf' object Functions that are
  used to tabulate categorical variables and compute
  moments for numeric variables inside through the
  MapReduce framework.  Used in
  <code><a href='#updateattributes'>updateAttributes</a></code>.</dd>
  <dt>result,reduce.values</dt>
  <dd>inconsequential
  <code>tabulateReduce</code> parameters</dd>
  <dt>y,order,na.rm</dt>
  <dd>inconsequential
  <code>calculateMoments</code> parameters</dd>
  <dt>m1,m2</dt>
  <dd>inconsequential <code>combineMoments</code>
  parameters</dd>
  <dt>...</dt>
  <dd>inconsequential parameters</dd>
  <dt>m</dt>
  <dd>inconsequential <code>moments2statistics</code>
  parameters</dd>
</dl>

  <h5>Description</h5>

  <p>Functions to Compute Summary Statistics in MapReduce</p>



</div>


<!-- print.ddo -->   
<div class="tab-pane" id="printddo">

<h3 class="fref_title">Print a "ddo" or "ddf" Object</h3>

<h5>Usage</h5>
<pre>print(x, ...)</pre>

<h5>Arguments</h5>
<dl>
  <dt>x</dt>
  <dd>object to be printed</dd>
  <dt>...</dt>
  <dd>additional arguments</dd>
</dl>

  <h5>Description</h5>

  <p>Print an overview of attributes of distributed data objects
(ddo) or distributed data frames (ddf)</p>




<h5>Author</h5>

Ryan Hafen

</div>


<!-- quantile.ddf -->   
<div class="tab-pane" id="quantileddf">

<h3 class="fref_title">Sample Quantiles for 'ddf' Objects</h3>

<h5>Usage</h5>
<pre>quantile(x, var, by = NULL, probs = seq(0, 1, 0.005), transFn = identity, nBins = 10000, 
  tails = 100, control = NULL, ...)</pre>

<h5>Arguments</h5>
<dl>
  <dt>x</dt>
  <dd>a 'ddf' object</dd>
  <dt>var</dt>
  <dd>the name of the variable to compute quantiles
  for</dd>
  <dt>by</dt>
  <dd>the (optional) variable by which to group
  quantile computations</dd>
  <dt>probs</dt>
  <dd>numeric vector of probabilities with values
  in [0-1]</dd>
  <dt>transFn</dt>
  <dd>transformation to apply to variable prior
  to computing quantiles</dd>
  <dt>nBins</dt>
  <dd>how many bins should the range of the
  variable be split into?</dd>
  <dt>tails</dt>
  <dd>how many exact values at each tail should be
  retained?</dd>
  <dt>control</dt>
  <dd>parameters specifying how the backend
  should handle things (most-likely parameters to
  <code>rhwatch</code> in RHIPE) - see <code><a href='#rhipecontrol'>rhipeControl</a></code>
  and <code><a href='#localdiskcontrol'>localDiskControl</a></code></dd>
  <dt>...</dt>
  <dd>additional arguments</dd>
</dl>

  <h5>Value</h5>

  <p>data frame of quantiles <code>q</code> and their associated
f-value <code>fval</code>.  If <code>by</code> is specified, then also
a variable <code>group</code>.</p>


  <h5>Description</h5>

  <p>Compute sample quantiles for 'ddf' objects</p>


  <h5>Details</h5>

  <p>This division-agnostic quantile calculation algorithm takes
the range of the variable of interest and splits it into
<code>nBins</code> bins, tabulates counts for those bins, and
reconstructs a quantile approximation from them.
<code>nBins</code> should not get too large, but larger
<code>nBins</code> gives more accuracy.  If <code>tails</code> is
positive, the first and last <code>tails</code> ordered values
are attached to the quantile estimate - this is useful for
long-tailed distributions or distributions with outliers
for which you would like more detail in the tails.</p>




<h5>See also</h5>

<code><a href='#updateattributes'>updateAttributes</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- readHDFStextFile -->   
<div class="tab-pane" id="readhdfstextfile">

<h3 class="fref_title">Experimental HDFS text reader helper function</h3>

<h5>Usage</h5>
<pre>readHDFStextFile(input, output = NULL, fn = NULL, keyFn = NULL, linesPerBlock = 10000, 
  control = NULL, update = FALSE)</pre>

<h5>Arguments</h5>
<dl>
  <dt>input</dt>
  <dd>a RHIPE input text handle created with
  <code>rhfmt</code></dd>
  <dt>output</dt>
  <dd>an output connection such as those created
  with <code><a href='#localdiskconn'>localDiskConn</a></code>, and
  <code><a href='#hdfsconn'>hdfsConn</a></code></dd>
  <dt>fn</dt>
  <dd>function to be applied to each chunk of lines
  (input to function is a vector of strings)</dd>
  <dt>keyFn</dt>
  <dd>optional function to determine the value of
  the key for each block</dd>
  <dt>linesPerBlock</dt>
  <dd>how many lines at a time to read</dd>
  <dt>control</dt>
  <dd>parameters specifying how the backend
  should handle things (most-likely parameters to
  <code>rhwatch</code> in RHIPE) - see <code><a href='#rhipecontrol'>rhipeControl</a></code>
  and <code><a href='#localdiskcontrol'>localDiskControl</a></code></dd>
  <dt>update</dt>
  <dd>should a MapReduce job be run to obtain
  additional attributes for the result data prior to
  returning?</dd>
</dl>

  <h5>Description</h5>

  <p>Experimental helper function for reading text data on HDFS
into a HDFS connection</p>



</div>


<!-- readTextFileByChunk -->   
<div class="tab-pane" id="readtextfilebychunk">

<h3 class="fref_title">Experimental sequential text reader helper function</h3>

<h5>Usage</h5>
<pre>readTextFileByChunk(input, output, linesPerBlock = 10000, fn = NULL, header = TRUE, 
  skip = 0, recordEndRegex = NULL)</pre>

<h5>Arguments</h5>
<dl>
  <dt>input</dt>
  <dd>the path to an input text file</dd>
  <dt>output</dt>
  <dd>an output connection such as those created
  with <code><a href='#localdiskconn'>localDiskConn</a></code>, and
  <code><a href='#hdfsconn'>hdfsConn</a></code></dd>
  <dt>linesPerBlock</dt>
  <dd>how many lines at a time to read</dd>
  <dt>fn</dt>
  <dd>function to be applied to each chunk of lines
  (see details)</dd>
  <dt>header</dt>
  <dd>does the file have a header</dd>
  <dt>skip</dt>
  <dd>number of lines to skip before reading</dd>
  <dt>recordEndRegex</dt>
  <dd>an optional regular expression that
  finds lines in the text file that indicate the end of a
  record (for multi-line records)</dd>
</dl>

  <h5>Description</h5>

  <p>Experimental helper function for reading text data
sequentially from a file on disk and adding to connection
using <code><a href='#adddata'>addData</a></code></p>


  <h5>Details</h5>

  <p>The function <code>fn</code> should have one argument, which
should expect to receive a vector of strings, each element
of which is a line in the file.  It is also possible for
<code>fn</code> to take two arguments, in which case the second
argument is the header line from the file (some parsing
methods might need to know the header).</p>



</div>


<!-- recombine -->   
<div class="tab-pane" id="recombine">

<h3 class="fref_title">Recombine</h3>

<h5>Usage</h5>
<pre>recombine(data, apply = NULL, combine = NULL, output = NULL, control = NULL, verbose = TRUE)</pre>

<h5>Arguments</h5>
<dl>
  <dt>data</dt>
  <dd>an object of class "ddo" of "ddf"</dd>
  <dt>apply</dt>
  <dd>a function specifying the analytic method to
  apply to each subset, or a pre-defined apply function
  (see <code><a href='#drblb'>drBLB</a></code>, <code><a href='#drglm'>drGLM</a></code>, for
  example)</dd>
  <dt>combine</dt>
  <dd>the method to combine the results</dd>
  <dt>output</dt>
  <dd>a "kvConnection" object indicating where
  the output data should reside (see
  <code><a href='#localdiskconn'>localDiskConn</a></code>, <code><a href='#hdfsconn'>hdfsConn</a></code>).  If
  <code>NULL</code> (default), output will be an in-memory "ddo"
  object.</dd>
  <dt>control</dt>
  <dd>parameters specifying how the backend
  should handle things (most-likely parameters to
  <code>rhwatch</code> in RHIPE) - see <code><a href='#rhipecontrol'>rhipeControl</a></code>
  and <code><a href='#localdiskcontrol'>localDiskControl</a></code></dd>
  <dt>verbose</dt>
  <dd>logical - print messages about what is
  being done</dd>
</dl>

  <h5>Value</h5>

  <p>depends on <code>combine</code></p>


  <h5>Description</h5>

  <p>Apply an analytic recombination method to a ddo/ddf object
and combine the results</p>


  <h5>References</h5>

  <p><ul>
<li> <a href = 'http://www.datadr.org'>http://www.datadr.org</a> </li>
<li>
<a href = 'http://onlinelibrary.wiley.com/doi/10.1002/sta4.7/full'>Guha,
S., Hafen, R., Rounds, J., Xia, J., Li, J., Xi, B., &
Cleveland, W. S. (2012). Large complex data: divide and
recombine (D&R) with RHIPE. <em>Stat</em>, 1(1), 53-67.</a> </li>
</ul></p>

  <p></p>




<h5>See also</h5>

<code><a href='#divide'>divide</a></code>, <code><a href='#ddo'>ddo</a></code>, <code><a href='#ddf'>ddf</a></code>,
<code><a href='#drglm'>drGLM</a></code>, <code><a href='#drblb'>drBLB</a></code>,
<code><a href='#combmeancoef'>combMeanCoef</a></code>, <code><a href='#combmean'>combMean</a></code>,
<code><a href='#combcollect'>combCollect</a></code>, <code><a href='#combrbind'>combRbind</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- removeData -->   
<div class="tab-pane" id="removedata">

<h3 class="fref_title">Remove Key-Value Pairs from a Data Connection</h3>

<h5>Usage</h5>
<pre>removeData(conn, keys)</pre>

<h5>Arguments</h5>
<dl>
  <dt>conn</dt>
  <dd>a kvConnection object</dd>
  <dt>keys</dt>
  <dd>a list of keys indicating which k/v pairs to
  remove</dd>
</dl>

  <h5>Description</h5>

  <p>Remove key-value pairs from a data connection</p>


  <h5>Note</h5>

  <p>This is generally not recommended for HDFS as it writes a
new file each time it is called, and can result in more
individual files than Hadoop likes to deal with.</p>




<h5>See also</h5>

<code><a href='#removedata'>removeData</a></code>, <code><a href='#localdiskconn'>localDiskConn</a></code>,
<code><a href='#hdfsconn'>hdfsConn</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- rhipeControl -->   
<div class="tab-pane" id="rhipecontrol">

<h3 class="fref_title">Specify Control Parameters for RHIPE Job</h3>

<h5>Usage</h5>
<pre>rhipeControl(mapred = NULL, setup = NULL, combiner = FALSE, cleanup = NULL, orderby = "bytes", 
  shared = NULL, jarfiles = NULL, zips = NULL, jobname = "")</pre>

<h5>Arguments</h5>
<dl>
  <dt>mapred,setup,combiner,cleanup,orderby,shared,jarfiles,zips,jobname</dt>
  <dd>arguments
  to <code>rhwatch</code> in RHIPE</dd>
</dl>

  <h5>Description</h5>

  <p>Specify control parameters for a RHIPE job.  See
<code>rhwatch</code> for details about each of the parameters.</p>



</div>


<!-- rrDiv -->   
<div class="tab-pane" id="rrdiv">

<h3 class="fref_title">Random Replicate Division</h3>

<h5>Usage</h5>
<pre>rrDiv(nrows = NULL, seed = NULL)</pre>

<h5>Arguments</h5>
<dl>
  <dt>nrows</dt>
  <dd>number of rows each subset should have</dd>
  <dt>seed</dt>
  <dd>the random seed to use (experimental)</dd>
</dl>

  <h5>Value</h5>

  <p>a list to be used for the "by" argument to
<code><a href='#divide'>divide</a></code></p>


  <h5>Description</h5>

  <p>Specify random replicate division parameters for data
division</p>


  <h5>Details</h5>

  <p>The random replicate division method currently gets the
total number of rows of the input data and divides it by
<code>nrows</code> to get the number of subsets.  Then it
randomly assigns each row of the input data to one of the
subsets, resulting in subsets with approximately
<code>nrows</code> rows.  A future implementation will make each
subset have exactly <code>nrows</code> rows.</p>


  <h5>References</h5>

  <p><ul>
<li> <a href = 'http://www.datadr.org'>http://www.datadr.org</a> </li>
<li>
<a href = 'http://onlinelibrary.wiley.com/doi/10.1002/sta4.7/full'>Guha,
S., Hafen, R., Rounds, J., Xia, J., Li, J., Xi, B., &
Cleveland, W. S. (2012). Large complex data: divide and
recombine (D&R) with RHIPE. <em>Stat</em>, 1(1), 53-67.</a> </li>
</ul></p>

  <p></p>




<h5>See also</h5>

<code><a href='#divide'>divide</a></code>, <code><a href='#recombine'>recombine</a></code>,
<code><a href='#conddiv'>condDiv</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


<!-- updateAttributes -->   
<div class="tab-pane" id="updateattributes">

<h3 class="fref_title">Update Attributes of a 'ddo' or 'ddf' Object</h3>

<h5>Usage</h5>
<pre>updateAttributes(obj, control = NULL)</pre>

<h5>Arguments</h5>
<dl>
  <dt>obj</dt>
  <dd>an object of class 'ddo' or 'ddf'</dd>
  <dt>control</dt>
  <dd>parameters specifying how the backend
  should handle things (most-likely parameters to
  <code>rhwatch</code> in RHIPE) - see
  <code><a href='#rhipecontrol'>rhipeControl</a></code></dd>
</dl>

  <h5>Value</h5>

  <p>an object of class 'ddo' or 'ddf'</p>


  <h5>Description</h5>

  <p>Update attributes of a 'ddo' or 'ddf' object</p>


  <h5>Details</h5>

  <p>This function looks for missing attributes related to a ddo
or ddf (distributed data object or data frame) object and
runs MapReduce to update them.  These attributes include
"splitSizeDistn", "keys", "nDiv", "nRow", and
"splitRowDistn".  These attributes are useful for
subsequent computations that might rely on them.  The
result is the input modified to reflect the updated
attributes, and thus it should be used as <code>obj <-
updateAttributes(obj)</code>.</p>


  <h5>References</h5>

  <p>Bennett, Janine, et al. "Numerically stable, single-pass,
parallel statistics algorithms." Cluster Computing and
Workshops, 2009. <em>CLUSTER'09. IEEE International
Conference on.</em> IEEE, 2009.</p>




<h5>See also</h5>

<code><a href='#ddo'>ddo</a></code>, <code><a href='#ddf'>ddf</a></code>, <code><a href='#divide'>divide</a></code>


<h5>Author</h5>

Ryan Hafen

</div>


   
   
   <ul class="pager">
      <li><a href="#" id="previous">&larr; Previous</a></li> 
      <li><a href="#" id="next">Next &rarr;</a></li> 
   </ul>
</div>


</div>
</div>

<hr>

<div class="footer">
   <p>&copy; Ryan Hafen, 2013</p>
</div>
</div> <!-- /container -->

<script src="js/jquery.js"></script>
<script src="bootstrap/js/bootstrap.js"></script>
<script src="js/jquery.ba-hashchange.min.js"></script>
<script>
function manageNextPrev() {
   $('a#next').parent().toggleClass('disabled', $('#toc.nav li.active').nextAll('li:not(.nav-header)').size() == 0);
   $('a#previous').parent().toggleClass('disabled', $('#toc.nav li.active').prevAll('li:not(.nav-header)').size() == 0);
   $("html, body").animate({ scrollTop: 0 }, "fast");
}
manageNextPrev();

$('a#next').click(function(e) {
   e.preventDefault();
   location.href = $('#toc.nav li.active').nextAll('li:not(.nav-header)').first().find('a').attr('href');
   manageNextPrev();
});
$('a#previous').click(function(e) {
   e.preventDefault();
   location.href = $('#toc.nav li.active').prevAll('li:not(.nav-header)').first().find('a').attr('href');
   manageNextPrev();
});

$(window).hashchange(function() {
  $('.tab-pane').hide();
  var tab = location.hash || '#packagemain';
  $(tab + '.tab-pane').show();

  $('#toc.nav li.active').removeClass('active');
  $('#toc.nav li a[href="' + tab + '"]').parent().addClass('active');
  manageNextPrev();
});
$(window).hashchange();

$('li.nav-header').dblclick(function(e) {
   var url = $(this).data('edit-href');
   if(url!="")
      window.open(url, '', '');
   return false;
});

</script>
</body>
</html>